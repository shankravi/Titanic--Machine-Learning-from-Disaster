{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submit = pd.read_csv('gender_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test['Cabin'].isna()==True,'Cabin'] = 'Z'\n",
    "train.loc[train['Cabin'].isna()==True,'Cabin'] = 'Z'\n",
    "def split(word):\n",
    "    return [char for char in word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the title\n",
    "train['Title'] = train['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n",
    "test['Title'] = test['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify code using encode = ['Sex','AgeRange','Cabin']\n",
    "dummies = pd.get_dummies(train.Sex)\n",
    "for i in train['Sex'].unique():\n",
    "    train[i] = 0\n",
    "for i in train['Sex'].unique():\n",
    "    train.loc[:,i] =  dummies[i]\n",
    "#train = train.drop(['Sex'], axis=1) \n",
    "train.head()\n",
    "dummies = pd.get_dummies(test.Sex)\n",
    "for i in test['Sex'].unique():\n",
    "    test[i] = 0\n",
    "for i in test['Sex'].unique():\n",
    "    test.loc[:,i] =  dummies[i]\n",
    "#test = test.drop(['Sex'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mr', 'Mrs', 'Miss', 'Master', 'Don', 'Rev', 'Dr', 'Mme', 'Ms',\n",
       "       'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'the Countess',\n",
       "       'Jonkheer'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['Embarked'].isna()==True][['Name','Sex','Ticket','Embarked','Cabin']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " After google one of the passengers (https://www.encyclopedia-titanica.org/titanic-survivor/martha-evelyn-stone.html) found that the Embarked value is 'S' since the other passenger has the same ticket number means they travelled together and so both Embarked from the same location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Embarked'] = train['Embarked'].fillna('S')\n",
    "# one hot encoding for Embarked\n",
    "dummies = pd.get_dummies(train.Embarked)\n",
    "for i in train['Embarked'].unique():\n",
    "    train[i+'E'] = 0\n",
    "for i in train['Embarked'].unique():\n",
    "    train.loc[:,i+'E'] =  dummies[i]\n",
    "dummies = pd.get_dummies(test.Embarked)\n",
    "for i in test['Embarked'].unique():\n",
    "    test[i+'E'] = 0\n",
    "for i in test['Embarked'].unique():\n",
    "    test.loc[:,i+'E'] =  dummies[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Ticket_freq'] = train.groupby('Ticket')['Ticket'].transform('count')\n",
    "test['Ticket_freq'] = test.groupby('Ticket')['Ticket'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cabin   A10  A14  A16  A19  A20  A23  A24  A26  A31  A32  ...  F E69  F G63  \\\n",
      "Pclass                                                    ...                 \n",
      "1       1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...    0.0    0.0   \n",
      "2       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
      "3       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    1.0    1.0   \n",
      "\n",
      "Cabin   F G73   F2  F33  F38   F4   G6    T      Z  \n",
      "Pclass                                              \n",
      "1         0.0  0.0  0.0  0.0  0.0  0.0  1.0   40.0  \n",
      "2         0.0  3.0  3.0  0.0  2.0  0.0  0.0  168.0  \n",
      "3         2.0  0.0  0.0  1.0  0.0  4.0  0.0  479.0  \n",
      "\n",
      "[3 rows x 148 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train.groupby('Pclass')['Cabin'].value_counts().unstack().fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
